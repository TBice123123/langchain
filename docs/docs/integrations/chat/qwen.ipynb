{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Qwen Qwen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatQwen\n",
    "\n",
    "This will help you get started with Qwen [chat models](../../concepts/chat_models.mdx). For detailed documentation of all ChatQwen features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: |  :---: | :---: | :---: |\n",
    "| [ChatQwen](https://pypi.org/project/langchain-qwq/) | [langchain-qwq](https://pypi.org/project/langchain-qwq/) | ❌ | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qwq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qwq?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](../../how_to/tool_calling.ipynb) | [Structured output](../../how_to/structured_output.ipynb) | JSON mode | [Image input](../../how_to/multimodal_inputs.ipynb) | Audio input | Video input | [Token-level streaming](../../how_to/chat_streaming.ipynb) | Native async | [Token usage](../../how_to/chat_token_usage_tracking.ipynb) | [Logprobs](../../how_to/logprobs.ipynb) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ✅ |✅  | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ | \n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Qwen models you'll need to create an Alibaba Cloud account, get an API key, and install the `langchain-qwq` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Alibaba's API Key page](https://account.alibabacloud.com/login/login.htm?oauth_callback=https%3A%2F%2Fbailian.console.alibabacloud.com%2F%3FapiKey%3D1&lang=en#/api-key) to sign up to Alibaba Cloud and generate an API key. Once you've done this set the `DASHSCOPE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter your Dashscope API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Qwen(by OpenAI API) integration lives in the `langchain-qwq` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-qwq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwen\n",
    "\n",
    "llm = ChatQwen(\n",
    "    model=\"qwen3-235b-a22b\",\n",
    "    max_tokens=3_000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # enable_thinking=False, # disable thinking\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={'reasoning_content': 'Okay, the user wants me to translate \"I love programming.\" into French. Let me start by breaking down the sentence. \"I love\" is straightforward; in French, that\\'s \"J\\'aime\". Now, \"programming\" can be a bit tricky. The direct translation might be \"programmation\", but sometimes people use \"coder\" in French to mean programming, especially in a more casual context. So, \"J\\'aime programmer\" would be \"I love to program\". Alternatively, \"la programmation\" is the noun form, so \"J\\'aime la programmation\" would mean \"I love programming\" as a general concept.\\n\\nI need to consider which is more appropriate. If the context is about the activity of programming itself, \"programmer\" as a verb might be better. But if it\\'s about the field or concept, \"programmation\" as a noun could work. However, in common usage, \"J\\'aime programmer\" sounds more natural and is often used. Also, \"coder\" is becoming more popular in French, similar to English, so maybe \"J\\'aime coder\" is another option. But the traditional translation would use \"programmer\". \\n\\nWait, but \"coder\" might be more colloquial. Let me check. In France, \"coder\" is commonly used, so \"J\\'aime coder\" is acceptable. However, \"programmer\" also means to program, but could sometimes be confused with \"to schedule\" in some contexts. So to avoid ambiguity, maybe \"coder\" is better. Hmm, but the original sentence is \"I love programming.\" as a general statement. Let me verify. \\n\\nLooking up examples, \"J\\'aime la programmation\" is a direct translation. However, \"J\\'aime programmer\" is also correct. The choice between noun and verb form might depend on nuance. Using the verb form \"programmer\" here might be more like \"I love to program\", while the noun form \"la programmation\" is \"I love programming\". Both are correct. But in French, using the verb might be more common. For example, \"J\\'aime danser\" (I love dancing) uses the verb. So following that structure, \"J\\'aime programmer\" would be analogous. \\n\\nAlternatively, \"coder\" is more about writing code, while \"programmer\" can have a broader meaning. But in the context of the user\\'s sentence, \"programming\" likely refers to coding. So both \"J\\'aime programmer\" and \"J\\'aime coder\" are acceptable. However, since the user asked for a translation, not a more colloquial version, maybe stick with the traditional \"programmer\". Therefore, the best translation would be \"J\\'aime programmer.\" \\n\\nWait, but wait. Let me check again. In French, \"programmation\" is the noun, so \"I love programming\" is \"J\\'aime la programmation\". But \"I love to program\" is \"J\\'aime programmer\". The user\\'s sentence is \"I love programming.\" as a statement, which could be either. However, \"programming\" here is a gerund, acting as a noun. So in French, using the infinitive might be more accurate. But in French, when expressing love for an activity, they often use the infinitive. So \"J\\'aime programmer\" would be correct. \\n\\nAlternatively, some might use \"la programmation\", but \"programmer\" is more active. Let me check a translation tool. Using Google Translate, \"I love programming\" is translated as \"J\\'aime programmer\". So that supports the verb form. Therefore, the correct translation is \"J\\'aime programmer.\" \\n\\nBut to be thorough, in some contexts, \"la programmation\" might be better. For example, if referring to programming as a field or discipline. But generally, \"J\\'aime programmer\" is natural. So I\\'ll go with \"J\\'aime programmer.\" as the translation.'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--daaba9d1-ef77-4927-8296-2443292c86b5-0', usage_metadata={'input_tokens': 32, 'output_tokens': 825, 'total_tokens': 857, 'input_token_details': {}, 'output_token_details': {'reasoning': 815}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French.\"\n",
    "        \"Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](../../how_to/sequence.ipynb) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe das Programmieren.', additional_kwargs={'reasoning_content': 'Okay, the user wants me to translate \"I love programming.\" into German. Let me think. The sentence is straightforward. \"I love\" in German is usually \"Ich liebe\" when talking about loving a person, but for activities or things, sometimes \"Ich mag\" is used. Wait, no, actually \"Ich liebe\" can also be used for strong affection towards activities. For example, \"Ich liebe Tanzen\" means \"I love dancing.\" So \"programming\" as an activity, \"Programmieren\" is the noun. So \"Ich liebe Programmieren.\" Alternatively, \"Ich liebe das Programmieren.\" But maybe the user prefers the shorter version without the article. Let me check. In German, both forms are correct. Sometimes using the article makes it clearer. Hmm. Also, \"programmieren\" is the verb, but in the noun form, it\\'s \"das Programmieren.\" So the correct translation would be \"Ich liebe das Programmieren.\" But sometimes people drop the article in informal speech. Wait, but in the original sentence, \"programming\" is a gerund, acting as a noun. So in German, adding the article might be more accurate. Let me confirm. Yes, \"Ich liebe das Programmieren.\" But maybe the user wants a direct translation. Let me see examples. For instance, \"I love cooking\" is \"Ich liebe das Kochen.\" So following that structure, \"I love programming\" would be \"Ich liebe das Programmieren.\" However, some might say \"Ich liebe Programmieren\" without the article. Both are acceptable, but with the article is more standard. I should provide the most accurate translation. So the answer should be \"Ich liebe das Programmieren.\" Alternatively, maybe \"Ich liebe es zu programmieren,\" but that\\'s more like \"I love to program.\" But the original is \"I love programming,\" which is a noun. So better to use the noun form. Yeah, \"Ich liebe das Programmieren.\" That\\'s the correct translation.\\n'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--e56b51a0-bbf3-4885-92fb-326f76cb75b8-0', usage_metadata={'input_tokens': 28, 'output_tokens': 417, 'total_tokens': 445, 'input_token_details': {}, 'output_token_details': {'reasoning': 406}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b3ef3",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "ChatQwQ supports tool calling API that lets you describe tools and their arguments, and have the model return a JSON object with a tool to invoke and the inputs to that tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1a355",
   "metadata": {},
   "source": [
    "### Use with `bind_tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fb6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What\\'s 5 times forty two\". Let me see. I need to multiply 5 by 42. The function provided is called multiply, which takes two integers. So first_int would be 5 and second_int is 42. I should call the multiply function with these values. Let me double-check the parameters: both are required and should be integers. Yep, that\\'s correct. So the tool call should have the name \"multiply\" and the arguments as first_int:5 and second_int:42. That should', 'tool_calls': [{'index': 0, 'id': 'call_e36584f044db4446a9947e', 'function': {'arguments': '{\"first_int\": 5, \"second_int\": 42}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen3-235b-a22b'} id='run--85e21d77-c5c3-4e2f-b505-b822ecd55a92-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_e36584f044db4446a9947e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 166, 'output_tokens': 150, 'total_tokens': 316, 'input_token_details': {}, 'output_token_details': {'reasoning': 118}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_qwq import ChatQwen\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatQwen(model=\"qwen3-235b-a22b\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"What's 5 times forty two\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a8d93",
   "metadata": {},
   "source": [
    "## Image Input\n",
    "ChatQwen can invoke the QwenVL visual model, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08cd91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The image shows a cute puppy with a light brown and white coat. The puppy has a white stripe down the middle of its face, white paws, and is standing on a soft surface. Its mouth is open, showing its tongue, and it appears to be looking directly at the camera with an alert and happy expression. The background is softly blurred, focusing attention on the puppy.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 1298, 'total_tokens': 1376, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': None, 'rejected_prediction_tokens': None, 'text_tokens': 78}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': None, 'text_tokens': 16, 'image_tokens': 1282}}, 'model_name': 'qwen2.5-vl-72b-instruct', 'system_fingerprint': None, 'id': 'chatcmpl-4e732a8b-4bbc-9722-b4a0-596fc979c0e9', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0eefd4e4-acdc-46ea-a2e0-1d5a7d88751b-0' usage_metadata={'input_tokens': 1298, 'output_tokens': 78, 'total_tokens': 1376, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_qwq import ChatQwen\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatQwen(model=\"qwen2.5-vl-72b-instruct\")\n",
    "\n",
    "response = model.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"http:example.com/image.png\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"What do you see in this image?\"},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQwen features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852df0a0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
